# -*- coding: utf-8 -*-
"""
Created on Wed Mar 16 23:34:04 2016
C4W2 Ramdom Forest
@author: cesar
"""

from pandas import Series, DataFrame
import pandas as pd
import numpy as np
import os
import matplotlib.pylab as plt
from sklearn.cross_validation import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
import sklearn.metrics
 # Feature Importance
from sklearn import datasets
from sklearn.ensemble import ExtraTreesClassifier

os.chdir("/home/cesar/Documentos/cesar/Profesional/Formacion/Wesleyan University/Machine Learning")

"""
Data Engineering and Analysis
"""
#Load the dataset
gapminder = pd.read_csv("/home/cesar/Documentos/cesar/Profesional/Formacion/Wesleyan University/Data Analysis Tools/gapminder.csv", low_memory=False)

gapminder['breastcancerper100th'] = gapminder['breastcancerper100th'].convert_objects(convert_numeric=True)
gapminder['co2emissions'] = gapminder['co2emissions'].convert_objects(convert_numeric=True)
gapminder['urbanrate'] = gapminder['urbanrate'].convert_objects(convert_numeric=True)
gapminder['incomeperperson'] = gapminder['incomeperperson'].convert_objects(convert_numeric=True)
gapminder['alcconsumption'] = gapminder['alcconsumption'].convert_objects(convert_numeric=True)
gapminder['femaleemployrate'] = gapminder['femaleemployrate'].convert_objects(convert_numeric=True)
gapminder['internetuserate'] = gapminder['internetuserate'].convert_objects(convert_numeric=True)
gapminder['relectricperperson'] = gapminder['relectricperperson'].convert_objects(convert_numeric=True)


data_clean = gapminder[['country','breastcancerper100th','co2emissions','urbanrate','incomeperperson','alcconsumption','femaleemployrate','internetuserate','relectricperperson']].dropna()

def Cancerbreast2BIN (x):
   if x['breastcancerper100th']>data_clean['breastcancerper100th'].mean():
      return 1
   else: 
      return 0
data_clean['Cancerbreast2BIN'] = data_clean.apply (lambda x: Cancerbreast2BIN (x), axis=1)

data_clean.dtypes
data_clean.describe()

"""
Modeling and Prediction
"""
#Split into training and testing sets

predictors = data_clean[['co2emissions','urbanrate','incomeperperson','alcconsumption','femaleemployrate','internetuserate','relectricperperson']]

targets = data_clean.Cancerbreast2BIN

pred_train, pred_test, tar_train, tar_test  =   train_test_split(predictors, targets, test_size=.4)

pred_train.shape
pred_test.shape
tar_train.shape
tar_test.shape

#Build model on training data
#Build model on training data
from sklearn.ensemble import RandomForestClassifier

classifier=RandomForestClassifier(n_estimators=25)
classifier=classifier.fit(pred_train,tar_train)

predictions=classifier.predict(pred_test)

sklearn.metrics.confusion_matrix(tar_test,predictions)
sklearn.metrics.accuracy_score(tar_test, predictions)


# fit an Extra Trees model to the data
model = ExtraTreesClassifier()
model.fit(pred_train,tar_train)
# display the relative importance of each attribute
print(model.feature_importances_)


"""
Running a different number of trees and see the effect
 of that on the accuracy of the prediction
"""

trees=range(25)
accuracy=np.zeros(25)

for idx in range(len(trees)):
   classifier=RandomForestClassifier(n_estimators=idx + 1)
   classifier=classifier.fit(pred_train,tar_train)
   predictions=classifier.predict(pred_test)
   accuracy[idx]=sklearn.metrics.accuracy_score(tar_test, predictions)
   
plt.cla()
plt.plot(trees, accuracy)
